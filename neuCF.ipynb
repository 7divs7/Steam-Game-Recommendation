{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL COLLABORATIVE FILTERING\n",
    "\n",
    "Combine GMF (capturing linearity) with MLP (capturing non-linearity) using concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dot, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.activations import relu, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>hours</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975370</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>51580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304390</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1085660</td>\n",
       "      <td>0.337073</td>\n",
       "      <td>253880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703080</td>\n",
       "      <td>0.027447</td>\n",
       "      <td>259432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>526870</td>\n",
       "      <td>0.007913</td>\n",
       "      <td>23869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>260230</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>9417270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>329430</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>2465811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>633230</td>\n",
       "      <td>0.038065</td>\n",
       "      <td>1893954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>341940</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>2465811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>335670</td>\n",
       "      <td>0.029049</td>\n",
       "      <td>2511774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16003 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        app_id     hours  user_id\n",
       "0       975370  0.036362    51580\n",
       "1       304390  0.011520     2586\n",
       "2      1085660  0.337073   253880\n",
       "3       703080  0.027447   259432\n",
       "4       526870  0.007913    23869\n",
       "...        ...       ...      ...\n",
       "15998   260230  0.007012  9417270\n",
       "15999   329430  0.002003  2465811\n",
       "16000   633230  0.038065  1893954\n",
       "16001   341940  0.001002  2465811\n",
       "16002   335670  0.029049  2511774\n",
       "\n",
       "[16003 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('datasets/training_set_recommendations.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NeuMF Model with Functional API\n",
    "def build_neumf_model(num_users, num_items, latent_dim_gmf, latent_dim_mlp, mlp_layers, dropout_rate_gmf, dropout_rate_mlp):\n",
    "    # Inputs\n",
    "    user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "    # GMF Embeddings\n",
    "    user_embedding_gmf = Embedding(input_dim=num_users, output_dim=latent_dim_gmf, name='gmf_user_embedding')(user_input)\n",
    "    item_embedding_gmf = Embedding(input_dim=num_items, output_dim=latent_dim_gmf, name='gmf_item_embedding')(item_input)\n",
    "    gmf_vector = tf.multiply(user_embedding_gmf, item_embedding_gmf)\n",
    "    gmf_vector = Flatten()(gmf_vector)\n",
    "    gmf_vector = Dropout(dropout_rate_gmf)(gmf_vector)\n",
    "\n",
    "    # MLP Embeddings\n",
    "    user_embedding_mlp = Embedding(input_dim=num_users, output_dim=latent_dim_mlp, name='mlp_user_embedding')(user_input)\n",
    "    item_embedding_mlp = Embedding(input_dim=num_items, output_dim=latent_dim_mlp, name='mlp_item_embedding')(item_input)\n",
    "    mlp_vector = Concatenate()([user_embedding_mlp, item_embedding_mlp])\n",
    "    mlp_vector = Flatten()(mlp_vector)\n",
    "\n",
    "    # MLP Layers\n",
    "    for in_size, out_size in zip(mlp_layers[:-1], mlp_layers[1:]):\n",
    "        mlp_vector = Dense(out_size, activation='relu')(mlp_vector)\n",
    "    mlp_vector = Dropout(dropout_rate_mlp)(mlp_vector)\n",
    "\n",
    "    # Combine GMF and MLP vectors\n",
    "    combined_vector = Concatenate()([gmf_vector, mlp_vector])\n",
    "    logits = Dense(1, activation='sigmoid')(combined_vector)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=[user_input, item_input], outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "df['user_id'], user_id_mapping = pd.factorize(df['user_id'])\n",
    "df['app_id'], app_id_mapping = pd.factorize(df['app_id'])\n",
    "n_users = df['user_id'].nunique()   # 2000\n",
    "n_items = df['app_id'].nunique()    # 3723\n",
    "embedding_dim_gmf = 10\n",
    "embedding_dim_mlp = 20\n",
    "\n",
    "# Parameters for MLP layers\n",
    "mlp_layers = [embedding_dim_mlp * 2, 128, 64]  # Example layers configuration\n",
    "dropout_rate_gmf = 0.2\n",
    "dropout_rate_mlp = 0.2\n",
    "\n",
    "# Build and compile the NeuMF model\n",
    "model = build_neumf_model(\n",
    "    num_users=n_users,\n",
    "    num_items=n_items,\n",
    "    latent_dim_gmf=embedding_dim_gmf,\n",
    "    latent_dim_mlp=embedding_dim_mlp,\n",
    "    mlp_layers=mlp_layers,\n",
    "    dropout_rate_gmf=dropout_rate_gmf,\n",
    "    dropout_rate_mlp=dropout_rate_mlp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example data preparation (replace with your actual data)\n",
    "user_indices = np.array(df['user_id'])\n",
    "item_indices = np.array(df['app_id'])\n",
    "y_train = np.array(df['hours'])  # Note: Ensure the target is binary if using binary_crossentropy\n",
    "\n",
    "# Ensure y_train is in binary format if you are using binary_crossentropy\n",
    "y_train_binary = (y_train > 0.5).astype(int)  # Example threshold for binary conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "226/226 [==============================] - 2s 4ms/step - loss: 0.2489 - accuracy: 0.9423 - val_loss: 0.0550 - val_accuracy: 0.9950\n",
      "Epoch 2/10\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9491 - val_loss: 0.0594 - val_accuracy: 0.9950\n",
      "Epoch 3/10\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.1034 - accuracy: 0.9567 - val_loss: 0.0693 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9621 - val_loss: 0.0939 - val_accuracy: 0.9763\n",
      "Epoch 5/10\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9673 - val_loss: 0.0916 - val_accuracy: 0.9781\n",
      "Epoch 6/10\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9729 - val_loss: 0.0881 - val_accuracy: 0.9806\n",
      "Epoch 7/10\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9801 - val_loss: 0.1119 - val_accuracy: 0.9681\n",
      "Epoch 8/10\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.0403 - accuracy: 0.9840 - val_loss: 0.1125 - val_accuracy: 0.9731\n",
      "Epoch 9/10\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9885 - val_loss: 0.1458 - val_accuracy: 0.9650\n",
      "Epoch 10/10\n",
      "226/226 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.1409 - val_accuracy: 0.9675\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    [user_indices, item_indices], \n",
    "    y_train_binary,\n",
    "    epochs=10, \n",
    "    batch_size=64, \n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501/501 [==============================] - 1s 1ms/step - loss: 0.0288 - accuracy: 0.9942\n",
      "Loss: 0.028793761506676674\n",
      "Accuracy: 0.9941886067390442\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([user_indices, item_indices], y_train_binary)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 1ms/step\n",
      "Top recommended items for user 4: [1394   77 1215  159   39   47   18   37   65 2711]\n"
     ]
    }
   ],
   "source": [
    "def recommend_items_for_user(model, user_id, all_item_ids, df, num_recommendations=10):\n",
    "    # Get all item_ids user hasn't interacted with yet\n",
    "    interacted_items = df[df['user_id'] == user_id]['app_id'].tolist()\n",
    "    items_to_predict = [item for item in all_item_ids if item not in interacted_items]\n",
    "    \n",
    "    # Create an array of user_id repeated for each item to predict\n",
    "    user_array = np.array([user_id] * len(items_to_predict))\n",
    "    item_array = np.array(items_to_predict)\n",
    "    \n",
    "    # Predict the scores for this user and the remaining items\n",
    "    predictions = model.predict([user_array, item_array])\n",
    "    \n",
    "    # Sort the predictions to get the top items\n",
    "    top_indices = predictions.flatten().argsort()[-num_recommendations:][::-1]\n",
    "    top_item_ids = item_array[top_indices]\n",
    "    \n",
    "    return top_item_ids\n",
    "\n",
    "# Assuming `all_item_ids` is the list of all possible items\n",
    "all_item_ids = df['app_id'].unique()\n",
    "\n",
    "# Example: Recommend items for a specific user\n",
    "user_id = 4  # Replace with the user_id you want recommendations for\n",
    "top_recommendations = recommend_items_for_user(model, user_id, all_item_ids, df, num_recommendations=10)\n",
    "\n",
    "print(f\"Top recommended items for user {user_id}: {top_recommendations}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
